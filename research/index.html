<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Language" content="en">

    <meta name="author" content="Greg Anderson">
    <meta name="description" content="My research broadly covers the intersection of programming languages and machine learning. In particular, I am most interested in developing techniques for proving the safety of systems with machine learning components. My early work in this domain focused on using abstraction refinement to prove local robustness properties (PLDI&#39;19). More recently I have worked on incorporating ideas from PL research to develop a framework for deep reinforcement learning with formally guaranteed safety (NeurIPS&#39;20 and ICLR&#39;23).">
    <meta name="keywords" content="">

    

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Research"/>
<meta name="twitter:description" content="My research broadly covers the intersection of programming languages and machine learning. In particular, I am most interested in developing techniques for proving the safety of systems with machine learning components. My early work in this domain focused on using abstraction refinement to prove local robustness properties (PLDI&#39;19). More recently I have worked on incorporating ideas from PL research to develop a framework for deep reinforcement learning with formally guaranteed safety (NeurIPS&#39;20 and ICLR&#39;23)."/>

    <meta property="og:title" content="Research" />
<meta property="og:description" content="My research broadly covers the intersection of programming languages and machine learning. In particular, I am most interested in developing techniques for proving the safety of systems with machine learning components. My early work in this domain focused on using abstraction refinement to prove local robustness properties (PLDI&#39;19). More recently I have worked on incorporating ideas from PL research to develop a framework for deep reinforcement learning with formally guaranteed safety (NeurIPS&#39;20 and ICLR&#39;23)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://gavlegoat.github.io/research/" />
<meta property="article:published_time" content="2023-06-09T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-06-09T00:00:00+00:00" />


    
      <base href="https://gavlegoat.github.io/research/">
    
    <title>
  Research Â· Greg Anderson
</title>

    
      <link rel="canonical" href="https://gavlegoat.github.io/research/">
    

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.13.0/css/all.css" integrity="sha384-Bfad6CLCknfcloXFOyFnlgtENryhrpZCe29RTifKEixXQZ38WheV+i/6YWSzkz3V" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />

    
      
      
      <link rel="stylesheet" href="https://gavlegoat.github.io/css/coder.min.0e5ce5b959a68dfe0232c6ddcec1e8ef154517c968464707f3181c437fe611c0.css" integrity="sha256-DlzluVmmjf4CMsbdzsHo7xVFF8loRkcH8xgcQ3/mEcA=" crossorigin="anonymous" media="screen" />
    

    

    
      
        
        
        <link rel="stylesheet" href="https://gavlegoat.github.io/css/coder-dark.min.717236c74e0a5208ef73964a9f44c6b443b689a95b270d8b2a40d0c012460dac.css" integrity="sha256-cXI2x04KUgjvc5ZKn0TGtEO2ialbJw2LKkDQwBJGDaw=" crossorigin="anonymous" media="screen" />
      
    

    

    

    <link rel="icon" type="image/png" href="https://gavlegoat.github.io/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://gavlegoat.github.io/images/favicon-16x16.png" sizes="16x16">

    <meta name="generator" content="Hugo 0.76.5" />
  </head>
  
  
  
    
  
  <body class="colorscheme-auto"
        onload=""
  >
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="https://gavlegoat.github.io/">
      Greg Anderson
    </a>
    
      <span id="dark-mode-toggle" class="float-right">
        <i class="fas fa-adjust fa-fw"></i>
      </span>
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fas fa-bars fa-fw"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link" href="https://gavlegoat.github.io/about/">About</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="https://gavlegoat.github.io/research/">Research</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="https://gavlegoat.github.io/publications/">Publications</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="https://gavlegoat.github.io/teaching/">Teaching</a>
            </li>
          
        
        
        <li class="navigation-item separator">
          <span>|</span>
        </li>
      </ul>
    
  </section>
</nav>


      <div class="content">
        
  <section class="container page">
  <article>
    <header>
      <h1>Research</h1>
    </header>

    <p>My research broadly covers the intersection of programming languages and
machine learning. In particular, I am most interested in developing techniques
for proving the safety of systems with machine learning components. My early
work in this domain focused on using abstraction refinement to prove local
robustness properties (<a href="https://gavlegoat.github.io/papers/charon-pldi-19.pdf">PLDI'19</a>). More recently I
have worked on incorporating ideas from PL research to develop a framework for
deep reinforcement learning with formally guaranteed safety
(<a href="https://gavlegoat.github.io/papers/revel-neurips2020.pdf">NeurIPS'20</a> and <a href="https://gavlegoat.github.io/papers/spice.pdf">ICLR'23</a>).</p>
<p>In addition, I have also done some work on using machine learning to improve
program analysis and program synthesis tools. For example, the aformentioned
PLDI paper used machine learning to figure out how to perform abstraction
refinement. Before that I worked on a system which uses machine learning to
automatically learn appropriate predicates for a predicate abstraction based
synthesis tool (<a href="https://gavlegoat.github.io/papers/atlas-cav-18.pdf">CAV'18</a>).</p>

  </article>
</section>

  

      </div>

      
    </main>

    
      
      <script src="https://gavlegoat.github.io/js/dark-mode.min.0213e1773e6d1c5a644f847c67a6f8abac49a3776e2976f6008038af8c5b76a1.js"></script>
    

    

    

    

    

  </body>

</html>
