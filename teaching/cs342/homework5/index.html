<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Language" content="en">

    <meta name="author" content="Greg Anderson">
    <meta name="description" content="In this homework, we will implement a neural vision system for an autonomous driving agent in SuperTuxKart.
This assignment, as with all of the homework assignments, should be completed individually without sharing solutions, models, or ideas with other students. See details at the bottom of this page.
Setup and Starter Code Starter code for this assignment is provided here. For this assignment, you will also need to install python bindings for SuperTuxKart &ndash; these are available in the pip package PySuperTuxKart.">
    <meta name="keywords" content="">

    

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Homework 5"/>
<meta name="twitter:description" content="In this homework, we will implement a neural vision system for an autonomous driving agent in SuperTuxKart.
This assignment, as with all of the homework assignments, should be completed individually without sharing solutions, models, or ideas with other students. See details at the bottom of this page.
Setup and Starter Code Starter code for this assignment is provided here. For this assignment, you will also need to install python bindings for SuperTuxKart &ndash; these are available in the pip package PySuperTuxKart."/>

    <meta property="og:title" content="Homework 5" />
<meta property="og:description" content="In this homework, we will implement a neural vision system for an autonomous driving agent in SuperTuxKart.
This assignment, as with all of the homework assignments, should be completed individually without sharing solutions, models, or ideas with other students. See details at the bottom of this page.
Setup and Starter Code Starter code for this assignment is provided here. For this assignment, you will also need to install python bindings for SuperTuxKart &ndash; these are available in the pip package PySuperTuxKart." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://gavlegoat.github.io/teaching/cs342/homework5/" />
<meta property="article:published_time" content="2022-04-04T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-04-04T00:00:00+00:00" />


    
      <base href="https://gavlegoat.github.io/teaching/cs342/homework5/">
    
    <title>
  Homework 5 Â· Greg Anderson
</title>

    
      <link rel="canonical" href="https://gavlegoat.github.io/teaching/cs342/homework5/">
    

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.13.0/css/all.css" integrity="sha384-Bfad6CLCknfcloXFOyFnlgtENryhrpZCe29RTifKEixXQZ38WheV+i/6YWSzkz3V" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />

    
      
      
      <link rel="stylesheet" href="https://gavlegoat.github.io/css/coder.min.0e5ce5b959a68dfe0232c6ddcec1e8ef154517c968464707f3181c437fe611c0.css" integrity="sha256-DlzluVmmjf4CMsbdzsHo7xVFF8loRkcH8xgcQ3/mEcA=" crossorigin="anonymous" media="screen" />
    

    

    
      
        
        
        <link rel="stylesheet" href="https://gavlegoat.github.io/css/coder-dark.min.717236c74e0a5208ef73964a9f44c6b443b689a95b270d8b2a40d0c012460dac.css" integrity="sha256-cXI2x04KUgjvc5ZKn0TGtEO2ialbJw2LKkDQwBJGDaw=" crossorigin="anonymous" media="screen" />
      
    

    

    

    <link rel="icon" type="image/png" href="https://gavlegoat.github.io/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://gavlegoat.github.io/images/favicon-16x16.png" sizes="16x16">

    <meta name="generator" content="Hugo 0.76.5" />
  </head>
  
  
  
    
  
  <body class="colorscheme-auto"
        onload=""
  >
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="https://gavlegoat.github.io/">
      Greg Anderson
    </a>
    
      <span id="dark-mode-toggle" class="float-right">
        <i class="fas fa-adjust fa-fw"></i>
      </span>
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fas fa-bars fa-fw"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link" href="https://gavlegoat.github.io/about/">About</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="https://gavlegoat.github.io/research/">Research</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="https://gavlegoat.github.io/publications/">Publications</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="https://gavlegoat.github.io/teaching/">Teaching</a>
            </li>
          
        
        
        <li class="navigation-item separator">
          <span>|</span>
        </li>
      </ul>
    
  </section>
</nav>


      <div class="content">
        
  <section class="container page">
  <article>
    <header>
      <h1>Homework 5</h1>
    </header>

    <p>In this homework, we will implement a neural vision system for an autonomous
driving agent in SuperTuxKart.</p>
<p>This assignment, as with all of the homework assignments, should be completed
individually without sharing solutions, models, or ideas with other students.
See details at the bottom of this page.</p>
<h1 id="setup-and-starter-code">Setup and Starter Code</h1>
<p>Starter code for this assignment is provided <a href="https://gavlegoat.github.io/cs342-homeworks/hw5.zip">here</a>.
For this assignment, you will also need to install python bindings for
SuperTuxKart &ndash; these are available in the pip package <code>PySuperTuxKart</code>.</p>
<p>If you are using Google Colab for training, you will need a slightly different
starter notebook than we have used for previous assignments. That notebook is
<a href="https://gavlegoat.github.io/cs342-notebooks/hw5_colab.ipynb">here</a>.</p>
<p>Note: if you are working in a Windows environment, we recommend using Anaconda
to set up an environment for this homework. The PySuperTuxKart package has some
annoying compilation details which are handled by Anaconda. In order to do
this, you can create a new conda environment then use the <code>environment.yml</code>
file included with the starter code to install all dependencies except
PySuperTuxKart. After that, install PySuperTuxKart through pip.</p>
<p>If you have any problems setting up the environment, please post them on
Piazza.</p>
<h1 id="controller-30pts">Controller (30pts)</h1>
<p>In the first part of this homework, you will write a handwritten controller in
<code>controller.py</code>. This controller takes an aim point and the current velocity of
the kart and should return a <code>pystk</code> action. The aim point is an (x, y) point
on the screen where (-1, -1) is the top left corner and (1, 1) is the bottom
right corner. This aim point is a point at the center of the track 15 meters
ahead of the current kart position, as in this image:</p>
<p><img src="https://gavlegoat.github.io/cs342-res/controller.png" alt="An aim point on a SuperTuxKart image"></p>
<p>For this part of the assignment, we will use the ground truth aim point
extracted directly from the simulator. In the next part of the homework, we
will replace this ground truth aim point by a point predicted by a neural
network.</p>
<p>The goal of this low-level controller is to steer the kart toward the aim
point. Your controller should return a <code>pystk.Action</code>. (This is the same type
of value we used in the in-class imitation learning exercise.) You can specify
the following values for the action:</p>
<ul>
<li><code>steer</code>: the steering angle of the kart &ndash; float in [-1, 1];</li>
<li><code>acceleration</code>: the acceleration of the kart &ndash; float in [0, 1];</li>
<li><code>brake</code>: whether or not to brake &ndash; boolean;</li>
<li><code>drift</code>: whether or not to drift, which can be useful in tight turns &ndash;
boolean; and</li>
<li><code>nitro</code>: whether to apply nitro for a boost of speed &ndash; boolean.</li>
</ul>
<p><em>This controller does not require any deep learning</em>. If you prefer to
implement this entirely within numpy without using PyTorch, that&rsquo;s totally
fine. Your controller may still have hyperparameters which you will want to
tune, but you won&rsquo;t need gradient descent.</p>
<p>You can test your finished controller with</p>
<pre><code>python -m homework.controller &lt;track_name&gt; -v
</code></pre>
<p>The reference solution completes the tracks in the following times:</p>
<ul>
<li><code>zengarden</code> and <code>lighthouse</code>: less than 50 seconds</li>
<li><code>hascienda</code> and <code>snowtuxpeak</code>: less than 60 seconds</li>
<li><code>cornfield_crossing</code> and <code>scotland</code>: less than 70 seconds</li>
</ul>
<p>Note that all of these are in-game times, and the wall-clock time may be a
little slower.</p>
<p>Hints:</p>
<ul>
<li>Add drift if the steering angle is too large (you&rsquo;ll need to experiment to
see what &ldquo;too large&rdquo; means).</li>
<li>Target a constant velocity</li>
<li>Steering and relative aim use different scales. Use the aim point and a
tuned scaling factor to choose the right amount of steering.</li>
<li>Make sure your controller can complete all tracks before moving on. The next
part of your homework uses this controller to build a training set, so it&rsquo;s
important that it works.</li>
</ul>
<h2 id="grading">Grading</h2>
<p>We will grade your homework on the following six tracks: hacienda, lighthouse,
cornfield_crossing, scotland, zengarden, and snowtuxpeak. The grading is split
up into 5pts per track, and your score on each track is proportional to how far
around the track your controller is able to get within a certain time limit.
The time limit is different for each track, you can find details inside
<code>grader/tests.py</code></p>
<h1 id="planner-70pts">Planner (70pts)</h1>
<p>In this part of the homework, you will train a CNN to select an aim point on
the image. This aim point will replace the ground truth label from the first
part to create a complete driving system.</p>
<h2 id="data">Data</h2>
<p>First, use your low-level controller to collect training data for your planner.
<strong>WARNING</strong>: This creates a dataset in the folder <code>drive_data</code>. Make sure to
back up any data that may be overwritten.</p>
<pre><code>python -m homework.utils zengarden lighthouse hacienda snowtuxpeak cornfield_crossing scotland
</code></pre>
<p>You may experiment with the list of levels used to generate data, but we
recommend this set. Adding additional levels may generate an unbalanced
training set and lead to some issues with the test grader.</p>
<p>You can visualize your training data with</p>
<pre><code>python -m homework.visualize_data drive_data
</code></pre>
<p>Here are some examples from the master solution:</p>
<p><img src="https://gavlegoat.github.io/cs342-res/data.png" alt="Data from the master solution to homework 5"></p>
<h2 id="model">Model</h2>
<p>You will now implement the <code>Planner</code> class in <code>planner.py</code>. The planner is a
<code>torch.nn.Module</code> which takes as input an image tensor and outputs the aim
point in the image coordinate (i.e., it should be a pair (x, y) of ints with x
in [0, 127] and y in [0, 95]). We recommend predicting a heatmap first and then
extracting the aim point using a spatial argmax layer as in the keypoint
exercise from class. Then write the training code in <code>train.py</code> and train as
usual with <code>python -m homework.train</code>.</p>
<h2 id="vision-based-driving">Vision-Based Driving</h2>
<p>Once you have completed all the parts of this homework, run</p>
<pre><code>python -m homework.planner &lt;track_name&gt; -v
</code></pre>
<p>to drive using your CNN planner and low-level controller.</p>
<h2 id="grading-1">Grading</h2>
<p>You will get up to 10pts each on the same six tracks that we use for testing
the low-level controller, using the same scoring system. The last 10 points
comes from an unseen test track which you did not train on. The test track is
relatively easy.</p>
<h2 id="extra-credit">Extra Credit</h2>
<p>We will run a tournament with all the submissions. The top nine submissions
will receive extra credit: first place gets 10 points, second gets 9 points,
and so on until ninth gets 1 point.</p>
<h1 id="validation-grader">Validation Grader</h1>
<p>As always, the validation grader can be run at any time with</p>
<pre><code>python -m grader homework -v
</code></pre>
<p>Note that this grader is using a different set of test data than we use for our
grader, so there may be some difference between the two. The distributions will
be the same so your grade should be similar between the two graders, unless the
model is massively overfit to the validation set.</p>
<h1 id="submission">Submission</h1>
<p>Once you are ready to submit, create a bundle by running</p>
<pre><code>python bundle.py homework &lt;eid&gt;
</code></pre>
<p>then submit the resulting zip file on Canvas. Note that the grader has a
maximum file size limit of 20MB. You shouldn&rsquo;t run into this limit unless your
models are much larger than they need to be. You can check that your homework
was bundled properly by grading it again with</p>
<pre><code>python -m grader &lt;eid&gt;.zip
</code></pre>
<h1 id="online-grader">Online Grader</h1>
<p>The online grading system uses a slightly modified version of Python, so please
make sure your code follows these rules:</p>
<ul>
<li>Do not use <code>exit</code> or <code>sys.exit</code> as this will likely crash the grader.</li>
<li>Do not try to access files except for the ones provided with the homework zip
file. Writing files is disabled.</li>
<li>Network access is disabled in the grader. Make sure you are reading your
dataset from the <code>data</code> folder rather than from a network connection
somewhere.</li>
<li>Do not fork or spawn new processes.</li>
<li><code>print</code> and <code>sys.stdout.write</code> are ignored by the grader.</li>
</ul>
<h1 id="honor-code">Honor Code</h1>
<p>You should do this homework individually. You are allowed to discuss high-level
ideas and general structure with each other, but not specific details about
code, architecture, or hyperparameters. You may consult online sources, but
don&rsquo;t copy code directly from any posts you find. Cite any ideas you take from
online sources in your code (include the full URL where you found the idea).
You may refer to your own solutions or the master solutions to prior homework
assignments from this class as well as any iPython notebooks from this class.
<strong>Do not put your solution in a public place (e.g., a public GitHub repo)</strong>.</p>
<h1 id="acknowledgements">Acknowledgements</h1>
<p>This assignment is very lightly modified from one created by Philipp
KrÃ¤henbÃ¼hl.</p>

  </article>
</section>

  

      </div>

      
    </main>

    
      
      <script src="https://gavlegoat.github.io/js/dark-mode.min.0213e1773e6d1c5a644f847c67a6f8abac49a3776e2976f6008038af8c5b76a1.js"></script>
    

    

    

    

    

  </body>

</html>
